import numpy as np
from onehot import onehot
from util import softmax, cosine
import time
class word2vec:
    def __init__(self, size, skip_gram=3, n_gram=5):
        self.__hidden_size = size
        self.__n_gram = n_gram
        self.__skip_gram = skip_gram

    def __loss(self, y_pred, y_true):
        """
        :y_pred is generated by the network
        :y_true is the index of the label
        """
        return -np.log(y_pred[y_true, 0])

    def __loss_grad(self, y_pred, y_true):
        tmp = y_pred.copy()
        tmp[y_true, 0] -= 1
        return np.mat(tmp)
    
    def __V_grad(self, loss_grad, hidden_value):
        return loss_grad * hidden_value

    def __W_grad(self, loss_grad):
        return self.__tmp_x_input * (loss_grad.transpose() * self.__V_weight)

    def __input_to_hidden(self, input_index, sentence):
        left = max(input_index - self.__n_gram, 0)
        right = min(input_index + self.__n_gram, len(sentence) - 1)
        hidden_value = np.mat(np.zeros((1, self.__hidden_size)))
        self.__C = right - left
        self.__tmp_x_input = np.mat(np.zeros((self.__voca_size, 1)))
        for index in range(left, right + 1):
            if index != input_index:
                i = self.__voca.get_index_of_word(sentence[index])
                self.__tmp_x_input[i, 0] = 1
                hidden_value += self.__W_weight[i]
        return hidden_value / (right - left)

    def __hidden_to_output(self, hidden_value):
        return softmax(self.__V_weight * hidden_value.transpose())

    def train(self, sentences, lr=0.01):
        if type(sentences) != list:
            print('Error type of sentences.')
            return
        self.__voca = onehot(sentences)
        self.__voca_size = self.__voca.get_voca_size()
        self.__W_weight = np.mat(np.random.rand(self.__voca_size, self.__hidden_size))
        self.__V_weight = np.mat(np.random.rand(self.__voca_size, self.__hidden_size))
        cnt = 0
        max_len = len(sentences)
        cnt_time = 0
        for sentence in sentences:
            time_start=time.time()
            for index in range(0, len(sentence)):
                hidden_value = self.__input_to_hidden(index, sentence)
                output_value = self.__hidden_to_output(hidden_value)
                loss_grad = self.__loss_grad(output_value, self.__voca.get_index_of_word(sentence[index]))
                W_grad = self.__W_grad(loss_grad)
                V_grad = self.__V_grad(loss_grad, hidden_value)
                self.__W_weight += lr * W_grad
                self.__V_weight += lr * V_grad
            time_end=time.time()
            print('A sentence time cost',time_end-time_start,'s')
            cnt_time += time_end - time_start
            cnt += 1
            if cnt % 100 == 0:
                loss = self.__loss(output_value, self.__voca.get_index_of_word(sentence[index]))
                print('{} / {} , loss is {}.'.format(cnt, max_len, loss))
        print('Avg time is {}'.format(cnt_time / max_len))

    def calc_similarity(self, w1, w2):
        index1 = self.__voca.get_index_of_word(w1)
        index2 = self.__voca.get_index_of_word(w2)
        return cosine(self.__W_weight[index1], self.__W_weight[index2])
